<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Wesley Tansey&#39;s implementation of a Reinforcement Learning agent for Tic-Tac-Toe : Fork of a Reinforcement Learning agent for Tic-Tac-Toe. Implements the example from Chapter 1 of Sutton and Barto.">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Wesley Tansey&#39;s implementation of a Reinforcement Learning agent for Tic-Tac-Toe</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/Naereen/Wesley-Tansey-RL-TicTacToe">View on GitHub</a>

          <h1 id="project_title">Wesley Tansey&#39;s implementation of a Reinforcement Learning agent for Tic-Tac-Toe</h1>
          <h2 id="project_tagline">Fork of a Reinforcement Learning agent for Tic-Tac-Toe. Implements the example from Chapter 1 of Sutton and Barto.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/Naereen/Wesley-Tansey-RL-TicTacToe/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/Naereen/Wesley-Tansey-RL-TicTacToe/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="reinforcement-learning-in-3x3-tic-tac-toe-learning-by-random-self-playing" class="anchor" href="#reinforcement-learning-in-3x3-tic-tac-toe-learning-by-random-self-playing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reinforcement Learning in 3x3 Tic-Tac-Toe, <em>learning by random self-playing</em>
</h1>

<blockquote>
<p>Implementation in Python (2 or 3), forked from <a href="https://github.com/tansey/rl-tictactoe">tansey/rl-tictactoe</a>.</p>
</blockquote>

<p>A quick Python implementation of the <strong>3x3</strong> <em>Tic-Tac-Toe</em> <strong>value function learning agent</strong> described in Chapter 1 of
<a href="http://webdocs.cs.ualberta.ca/%7Esutton/book/the-book.html">"Reinforcement Learning: An Introduction" by Sutton and Barto</a>.</p>

<hr>

<h3>
<a id="usage-of-this-program" class="anchor" href="#usage-of-this-program" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage of this program</h3>

<p>This implementation is simply <a href="tictactoe.py">one Python file (<code>tictactoe.py</code>)</a>:</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># Run this program and keep its output</span>
python2 tictactoe.py <span class="pl-k">|</span> tee ./tictactoe.log</pre></div>

<h3>
<a id="example" class="anchor" href="#example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example</h3>

<p>See the figure below for an example of what is achieved with this rather simple implementation:
<img src="https://raw.githubusercontent.com/Naereen/Wesley-Tansey-RL-TicTacToe/master/selfplay_random_-1loss.png" alt="Main example" title="Example of selfplay vs random"></p>

<p>Numerical results are also available in the (long) <a href="https://github.com/Naereen/Wesley-Tansey-RL-TicTacToe/blob/master/results.csv">results.csv</a> CSV file.</p>

<h3>
<a id="limitation" class="anchor" href="#limitation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Limitation</h3>

<blockquote>
<p>Only 3 by 3 (3x3) Tic-Tac-Toe is implemented.</p>
</blockquote>

<hr>

<h3>
<a id="explanations" class="anchor" href="#explanations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Explanations</h3>

<p>The agent contains a lookup table that maps states to values, where initial values are 1 for a win, 0 for a draw or loss, and 0.5 otherwise.
At every move, the agent chooses either the maximum-value move (greedy) or, with some probability epsilon, a random move (exploratory); by default <code>epsilon=0.1</code>.</p>

<p>The agent updates its value function (the lookup table) after every greedy move, following the equation:</p>

<pre><code>V(s) &lt;- V(s) + alpha * ( V(s') - V(s) )
</code></pre>

<h4>
<a id="why" class="anchor" href="#why" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why?</h4>

<p>This particular implementation addresses the question posed in Exercise 1.1:</p>

<blockquote>
<p>What would happen if the RL agent taught itself via self-play?</p>
</blockquote>

<p>The result is that the agent learns only how to maximize its own potential payoff,
without consideration for whether it is playing to a win or a draw.
Even more to the point, the agent learns a myopic strategy where it basically has a single path that it wants to take to reach a winning state.</p>

<p>If the path is blocked by the opponent, the values will then usually all become 0.5 and the player is effectively moving randomly (so we did nothing clever in this case).</p>

<p>Note that if you use a loss value of -1, then the agent learns to play the optimal strategy in the minimax sense.</p>

<hr>

<h3>
<a id="license-and-authors" class="anchor" href="#license-and-authors" aria-hidden="true"><span class="octicon octicon-link"></span></a>License and authors</h3>

<ul>
<li>Forked and cleaned up by <a href="https://github.com/Naereen">Lilian Besson (Naereen)</a>, 28/12/2015,</li>
<li>Created by <a href="https://github.com/tansey/">Wesley Tansey</a>, 1/21/2013,</li>
<li>Code released under the <a href="http://lbesson.mit-license.org">MIT license</a>.</li>
</ul>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Wesley Tansey&#39;s implementation of a Reinforcement Learning agent for Tic-Tac-Toe maintained by <a href="https://github.com/Naereen">Naereen</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-38514290-17");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>


  </body>
</html>
